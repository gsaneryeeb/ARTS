# 数据科学常用小函数(不定期更新)

Update: 2019-05-05

## 数据清洗

内容总结自: [The Simple Yet Practical Data Cleaning Codes](https://towardsdatascience.com/the-simple-yet-practical-data-cleaning-codes-ad27c4ce0a38)

### 1. Drop multiple columns

```python
def drop_multiple_col(col_names_list, df): 
    '''
    AIM    -> Drop multiple columns based on their column names 
    
    INPUT  -> List of column names, df
    
    OUTPUT -> updated df with dropped columns 
    ------
    '''
    df.drop(col_names_list, axis=1, inplace=True)
    return df
```

### 2. Change dtypes

```python

def change_dtypes(col_int, col_float, df): 
    '''
    AIM    -> Changing dtypes to save memory
     
    INPUT  -> List of column names (int, float), df
    
    OUTPUT -> updated df with smaller memory  
    ------
    '''
    df[col_int] = df[col_int].astype('int32')
    df[col_float] = df[col_float].astype('float32')

```

### 3. Convert categorical variable to numerical variable

```python
def convert_cat2num(df):
    # Convert categorical variable to numerical variable
    num_encode = {'col_1' : {'YES':1, 'NO':0},
                  'col_2'  : {'WON':1, 'LOSE':0, 'DRAW':0}}  
    df.replace(num_encode, inplace=True)  
```

### 4. Check missing data

```python
def check_missing_data(df):
    # check for any missing data in the df (display in descending order)
    return df.isnull().sum().sort_values(ascending=False)
```

### 5. Remove strings in columns

```python
def remove_col_str(df):
    # remove a portion of string in a dataframe column - col_1
    df['col_1'].replace('\n', '', regex=True, inplace=True)
    
    # remove all the characters after &# (including &#) for column - col_1
    df['col_1'].replace(' &#.*', '', regex=True, inplace=True)

```

### 6. Remove white space in columns

```python
def remove_col_white_space(df,col):
    # remove white space at the beginning of string 
    df[col] = df[col].str.lstrip()
```

### 7. Concatenate two columns with strings (with condition)

```python
def concat_col_str_condition(df):
    # concat 2 columns with strings if the last 3 letters of the first column are 'pil'
    mask = df['col_1'].str.endswith('pil', na=False)
    col_new = df[mask]['col_1'] + df[mask]['col_2']
    col_new.replace('pil', ' ', regex=True, inplace=True)  # replace the 'pil' with emtpy space
```

### 8. Convert timestamp(from string to datetime format)

```python
def convert_str_datetime(df): 
    '''
    AIM    -> Convert datetime(String) to datetime(format we want)
     
    INPUT  -> df
    
    OUTPUT -> updated df with new datetime format 
    ------
    '''
    df.insert(loc=2, column='timestamp', value=pd.to_datetime(df.transdate, format='%Y-%m-%d %H:%M:%S.%f')) 
```

## 数据加工

### 1. downcast dtypes

```python
def downcast_dtypes(df):
    '''
        Changes column types in the dataframe: 
                
                `float64` type to `float32`
                `int64`   type to `int32`
    '''

    # Select columns to downcast
    float_cols = [c for c in df if df[c].dtype == "float64"]
    int_cols = [c for c in df if df[c].dtype == "int64"]

    # Downcast
    df[float_cols] = df[float_cols].astype(np.float32)
    df[int_cols] = df[int_cols].astype(np.int32)

    return df
```

### 2. Lag features

```python
def lag_feature(df, lags, col):
    tmp = df[['date_block_num', 'shop_id', 'item_id', col]]
    for i in lags:
        shifted = tmp.copy()
        shifted.columns = [
            'date_block_num', 'shop_id', 'item_id', col + '_lag_' + str(i)
        ]
        shifted['date_block_num'] += i
        df = pd.merge(
            df,
            shifted,
            on=['date_block_num', 'shop_id', 'item_id'],
            how='left')
    return df
```

### 3. Mean encoded features

```python
def mean_feature_eng(df, index_cols, col_name):

    group = df.groupby(index_cols).agg({'item_cnt_month': ['mean']})
    group.columns = [col_name]
    group.reset_index(inplace=True)

    df = pd.merge(df, group, on=index_cols, how='left')
    df[col_name] = df[col_name].astype(np.float16)
    df = lag_feature(df, [1], col_name)
    df.drop([col_name], axis=1, inplace=True)

    return df
```

### 4. File Split

```python
#-*- coding:utf-8 -*-
#author:chenpeng
#date: 2017-11-07
#作用：根据需要拆分的文件数，拆分文件
#备注：可以拆分csv格式文件和txt格式文件，返回的数据均是没有表头
import os
import pandas

def file_split(filename, file_num, header=True):
    #根据是否有表头执行不同程序，默认是否表头的
    if header:
        # 获得每个文件需要有的行数
        chunksize = 1000000   #先初始化的chunksize是100W
        data1 = pd.read_table(filename, chunksize = chunksize, sep=',', encoding='gbk') 
        num = 0
        for chunk in data1:
            num += len(chunk)
        chunksize = round(num / file_num + 1)

        # 需要存的file
        head, tail = os.path.splitext(filename)
        data2 = pd.read_table(filename, chunksize = chunksize, sep=',', encoding='gbk')
        i = 0 #定文件名
        for chunk in data2:
            chunk.to_csv('{0}_{1}{2}'.format(head, i, tail),header=None,index=False)
            print('保存第{0}个数据'.format(i))
            i += 1
    else:
        # 获得每个文件需要有的行数
        chunksize = 1000000   #先初始化的chunksize是100W
        data1 = pd.read_table(filename, chunksize = chunksize ,header=None, sep=',') 
        num = 0
        for chunk in data1:
            num += len(chunk)
        chunksize = round(num / file_num + 1)

        # 需要存的file
        head, tail = os.path.splitext(filename)
        data2 = pd.read_table(filename, chunksize = chunksize ,header=None, sep=',')
        i = 0 #定文件名
        for chunk in data2:
            chunk.to_csv('{0}_{1}{2}'.format(head, i, tail),header=None,index=False)
            print('保存第{0}个数据'.format(i))
            i += 1
    
if __name__ == '__main__':
    filename = 'D:\\bigdata.csv'
    file_split(filename, 5, header=False)
```

### 5. Split Data

This function takes a SOURCE directory containing the files a TRAINING directory that a portion of the files will be copied to a TESTING directory that a portion of the files will be copie to a SPLIT SIZE to determine the portion

The files should also be randomized, so that the training set is a random X% of the files, and the test set is the remaining files

SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9 Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir and 10% of the images will be copied to the TESTING dir

Also -- All images should be checked, and if they have a zero file length,
they will not be copied over

```python
# Write a python function called split_data which takes
# a SOURCE directory containing the files
# a TRAINING directory that a portion of the files will be copied to
# a TESTING directory that a portion of the files will be copie to
# a SPLIT SIZE to determine the portion
# The files should also be randomized, so that the training set is a random
# X% of the files, and the test set is the remaining files
# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9
# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir
# and 10% of the images will be copied to the TESTING dir
# Also -- All images should be checked, and if they have a zero file length,
# they will not be copied over
#
# os.listdir(DIRECTORY) gives you a listing of the contents of that directory
# os.path.getsize(PATH) gives you the size of the file
# copyfile(source, destination) copies a file from source to destination
# random.sample(list, len(list)) shuffles a list
def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):
  
  files = []
  
  for filename in os.listdir(SOURCE):
    file = SOURCE + filename
    if os.path.getsize(file) > 0:
      files.append(filename)
    else:
      print(filename + " is zero length, so ignoring.")
      
  training_length = int(len(files) * SPLIT_SIZE)
  testing_length = int(len(files) - training_length)
  shuffled_set = random.sample(files, len(files))
  training_set = shuffled_set[0:training_length]
  testing_set = shuffled_set[-testing_length:]
  
  for filename in training_set:
    this_file = SOURCE + filename
    destination = TRAINING + filename
    copyfile(this_file, destination)
    
  for filename in testing_set:
    this_file = SOURCE + filename
    destination = TESTING + filename
    copyfile(this_file, destination)

CAT_SOURCE_DIR = "/tmp/PetImages/Cat/"
TRAINING_CATS_DIR = "/tmp/cats-v-dogs/training/cats/"
TESTING_CATS_DIR = "/tmp/cats-v-dogs/testing/cats/"
DOG_SOURCE_DIR = "/tmp/PetImages/Dog/"
TRAINING_DOGS_DIR = "/tmp/cats-v-dogs/training/dogs/"
TESTING_DOGS_DIR = "/tmp/cats-v-dogs/testing/dogs/"

split_size = .9
split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)
split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)

# Expected output
# 666.jpg is zero length, so ignoring
# 11702.jpg is zero length, so ignoring
```