# KazAnova's competition pipeline, part1

Notes of Coursera - [How to Win a Data Science Competition: Learn from Top Kagglers](https://www.coursera.org/learn/competitive-data-science?)

![1.png](data/1.png)

## Understand broadly the problem

- Type of problem: 

    - image classification 
    - sound classification
    - text classification
    - optimization problem
    - time series problem

- How BIG is the data(How much I need?)?
- Hardware needed (CPUs, GPUs, RAM, Disk space)
- Software Needed (TF, sklearn, Lightgbm, xgboost)
  
  create an anaconda enviroment for every task

- What is the metric being tested on?
  - Is it a regression program, is it a classification program, is it root mean square error, is it mean absoulre error?
  - find if there's any similar competition with similar type of data
- Previous code relevant?

## EDA (exploratory data analysis) (1-2 days)

- Plot histograms of variables. Check that a feature looks similar between train and test. If there are discrepancies or differences, I need to remove these variables or scale them in a specific way.

- Plot features versus the target and possibly versus time.

- Consider univariate predictability metrics (IV,R,auc): InformationValue - [ref1](http://r-statistics.co/Information-Value-With-R.html), [ref2](https://blog.csdn.net/kevin7658/article/details/50780391); AUC (Area Under ROC Curve) - [ref1](https://medium.com/kkstream/auc-explained-85537509e3b3)

- Binning numerical features and correlation matrices
  
  [Data binning](https://en.wikipedia.org/wiki/Data_binning)

  [correlation matrix](https://www.displayr.com/what-is-a-correlation-matrix/)

## Decide a cross validation Stratrgy

- This step is critical. Its success is a good indication for what is going to happen in the competition.

- People have won by just selecting the right way to validate.

- create a validation approach that best resembles what you're being tested on

- Key word: **Consistency**

- *Is time is important?* Split by time. **Time-based validation**.
  
  **Same time interval**: If the test data is three months in the future, You need to build your training and validation to account for this time interval. So your validation data always need to be three months in the future and compared to the training data. 

- *Different entities* than the train. **Stratified validation.**

  If you have different customers in the training data and different in the test data. You need to formulate your cross validation strategy so that in the validation data, you always have different customers running in training data otherwise you are not really testing in a fair way.
  
  *Am I making a validation which is really consisten with what am I being tested on?*

- *Is it completely random.* **Random validation**(random K-fold)

- **Combination** of all the above.
  - Start with a random validation
  - Use test leader board to test.

    See how **consistent** the result is with what they have internally, and see if improvements in my validation lead to improvements to the leader board.If that doesn't happen, I make a deeper investigation and try to understand why. It maybe that the time element is very strong and I need to take it into account or there are different entities between the train and test data.

## Feature engineering

- The type of problem defines the feature engineering.

- **Image classification**: Scaling, shifting, rotations, CNNs. Suggetion [previous data science bowls](https://www.kaggle.com/c/data-science-bowl-2018).

- **Sound classification**: Fourier, Mfcc, specgrams, scaling. [Tensoflow speech recognition](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge)

- **Text classification**: Tf-idf, SVD, stemming, spell checking, stop word's removal, x-grams.[StumbleUpon Evergreen Classification](https://www.kaggle.com/c/stumbleupon)

- **Time series:** Lags, weighted averaging, exponential smoothing. [Walmart recruitment](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting)

- **Categorical:** Target enc, freq, one-hot, ordinal, label encoding. [Amazon employee](https://www.kaggle.com/c/amazon-employee-access-challenge)

- **Numerical:** Scaling, binning, dervatives, outlier removals, dimensionality reduction. [Africa soil](https://www.kaggle.com/c/afsis-soil-properties)

- **Ineractions:** multiplications, divisions, group-by features. Concatenations. [Homesite](https://www.kaggle.com/c/homesite-quote-conversion)

- **Recommenders**: Features on transactional history. Item popularity, frequency of purchase. [Acquire Valued Shoppers](https://www.kaggle.com/c/acquire-valued-shoppers-challenge)

- This process **can be automated** using selection with cross validation.
