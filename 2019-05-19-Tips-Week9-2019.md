# 海量数据在神经网络中的分批训练 - Keras

对于过大的数据，无法一次载入内存进行训练，可以使用 Keras 提供的迭代器分批进行训练

1. 将训练数据按照适当的体积分割为多个 pickle 文件。

2. 构造 **generator**

   **官方 Example**

   ```python
   def generate_arrays_from_file(path):
    while True:
        with open(path) as f:
            for line in f:
                # create numpy arrays of input data
                # and labels, from each line in the file
                x1, x2, y = process_line(line)
                yield ({'input_1': x1, 'input_2': x2}, {'output': y})

   ```
   
   **My Example**
   
   ```python

   def generate_arrays_from_file(train_data_dir = '../train/', num_files = 1):
    # return a tuple(inputs, targets)

    files = sorted(file for file in os.listdir(train_data_dir) if not file.startswith('.'))
    count = num_files
    features, labels = [],[]
    for file in files:
        print('Reading file {0}............'.format(file))
        gc.collect()
        with open(train_data_dir + file, 'rb') as rf:
            data = pickle.load(rf)
        
        # 构造训练数据集 X，和结果集 Y

        yield(X,Y)

   ```


3. 使用 **fit_generator** 进行训练

   ```python
   model.fit_generator(generate_arrays_from_file(),
                    steps_per_epoch=10000, epochs=10)

   ```